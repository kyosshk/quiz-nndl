{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyosshk/quiz-nndl/blob/main/NNDL_quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgBslHbuArqE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape data to fit the model\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Define the CNN model function\n",
        "def create_model(learning_rate=0.001, optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create a KerasClassifier for GridSearchCV\n",
        "model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "# Define the parameters for grid search\n",
        "param_grid = {\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [32, 64],\n",
        "    'optimizer': ['adam', 'sgd']\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "# Define the final model with the best parameters\n",
        "best_learning_rate = grid_result.best_params_['learning_rate']\n",
        "best_batch_size = grid_result.best_params_['batch_size']\n",
        "best_optimizer = grid_result.best_params_['optimizer']\n",
        "\n",
        "final_model = create_model(learning_rate=best_learning_rate, optimizer=best_optimizer)\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = final_model.fit(X_train, y_train, epochs=10, batch_size=best_batch_size, validation_data=(X_test, y_test), callbacks=[reduce_lr])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = final_model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# Load the IMDb dataset\n",
        "max_features = 10000  # consider only the top 10,000 most common words\n",
        "maxlen = 200  # truncate reviews to 200 words\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the text data (padding)\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "# Define the RNN model function\n",
        "def create_model(learning_rate=0.001, optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32))\n",
        "    model.add(SimpleRNN(32))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create a KerasClassifier for GridSearchCV\n",
        "model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "# Define the parameters for grid search\n",
        "param_grid = {\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [32, 64],\n",
        "    'optimizer': ['adam', 'sgd']\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "# Define the final model with the best parameters\n",
        "best_learning_rate = grid_result.best_params_['learning_rate']\n",
        "best_batch_size = grid_result.best_params_['batch_size']\n",
        "best_optimizer = grid_result.best_params_['optimizer']\n",
        "\n",
        "final_model = create_model(learning_rate=best_learning_rate, optimizer=best_optimizer)\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = final_model.fit(X_train, y_train, epochs=10, batch_size=best_batch_size, validation_data=(X_test, y_test), callbacks=[reduce_lr])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = final_model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KjtqjqjLAtso"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}